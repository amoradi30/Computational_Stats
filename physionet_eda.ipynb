{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PhysioNet 2012 ICU Dataset â€” Exploratory Data Analysis\n",
        "\n",
        "This notebook inspects the PhysioNet 2012 Challenge data included in this repository. It focuses on demographic descriptors, feature availability, and example time-series behavior to build intuition for subsequent modeling work.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Import helper utilities and configure plotting defaults. The notebook reuses the data loading utilities from `dataloader.py` to stay consistent with the rest of the project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from dataloader import (\n",
        "    load_raw_dataset,\n",
        "    TIME_SERIES_VARIABLES,\n",
        "    compute_feature_missingness,\n",
        "    pivot_timeseries,\n",
        ")\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load general descriptors and time series\n",
        "Set paths relative to the repo root and load `set-a`, which includes the labeled training cohort used for model development.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "SET_NAME = \"set-a\"\n",
        "\n",
        "general_info_df, timeseries_dict = load_raw_dataset(DATA_DIR, SET_NAME, verbose=False)\n",
        "print(f\"Loaded {len(general_info_df)} patients from {SET_NAME} and {len(timeseries_dict)} time-series files.\")\n",
        "general_info_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demographic descriptors\n",
        "Look at the basic descriptors that are recorded for each ICU stay. The dataset encodes gender as 0=female, 1=male and ICUType as integer categories (1=Coronary Care, 2=Cardiac Surgery Recovery, 3=Medical ICU, 4=Surgical ICU).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "descriptor_cols = [\"Age\", \"Gender\", \"Height\", \"ICUType\", \"Weight\"]\n",
        "\n",
        "demographic_summary = general_info_df[descriptor_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
        "demographic_summary.describe(percentiles=[0.25, 0.5, 0.75])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "age_series = demographic_summary[\"Age\"].dropna()\n",
        "sns.histplot(age_series, bins=30, kde=True, ax=axes[0])\n",
        "axes[0].set_title(\"Age distribution\")\n",
        "axes[0].set_xlabel(\"Age (years)\")\n",
        "\n",
        "# Gender counts (0=female, 1=male per challenge docs)\n",
        "gender_counts = (\n",
        "    demographic_summary[\"Gender\"].map({0: \"Female\", 1: \"Male\"}).value_counts(dropna=True)\n",
        ")\n",
        "sns.barplot(x=gender_counts.index, y=gender_counts.values, ax=axes[1], palette=\"pastel\")\n",
        "axes[1].set_title(\"Gender counts\")\n",
        "axes[1].set_xlabel(\"\")\n",
        "axes[1].set_ylabel(\"Patients\")\n",
        "\n",
        "icu_map = {\n",
        "    1: \"CCU\",\n",
        "    2: \"Cardiac Surg\",\n",
        "    3: \"MICU\",\n",
        "    4: \"SICU\",\n",
        "}\n",
        "icu_counts = demographic_summary[\"ICUType\"].map(icu_map).value_counts(dropna=True)\n",
        "sns.barplot(x=icu_counts.index, y=icu_counts.values, ax=axes[2], palette=\"muted\")\n",
        "axes[2].set_title(\"ICU type distribution\")\n",
        "axes[2].set_xlabel(\"\")\n",
        "axes[2].set_ylabel(\"Patients\")\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measurement coverage per patient\n",
        "Count how many charted measurements exist per admission and visualize the distribution to understand how sparse the records are.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "measurement_counts = pd.Series({pid: len(ts) for pid, ts in timeseries_dict.items()})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "sns.histplot(measurement_counts, bins=40, ax=ax)\n",
        "ax.set_title(\"Recorded measurements per patient\")\n",
        "ax.set_xlabel(\"# charted rows (per ICU stay)\")\n",
        "ax.set_ylabel(\"Patients\")\n",
        "plt.tight_layout()\n",
        "\n",
        "measurement_counts.describe(percentiles=[0.25, 0.5, 0.75])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature availability / missingness\n",
        "Use the helper in `dataloader.py` to compute missingness for every time-series variable. Sorting the results highlights which labs and vitals are best populated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missingness = compute_feature_missingness(timeseries_dict, TIME_SERIES_VARIABLES)\n",
        "missingness_df = (\n",
        "    pd.Series(missingness, name=\"missing_rate\")\n",
        "    .sort_values()\n",
        "    .to_frame()\n",
        ")\n",
        "missingness_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 10))\n",
        "missingness_df[::-1].plot(kind=\"barh\", legend=False, ax=ax, color=\"steelblue\")\n",
        "ax.set_xlabel(\"Missing rate (fraction of charted time points without the feature)\")\n",
        "ax.set_ylabel(\"Variable\")\n",
        "ax.set_title(\"Feature missingness across training cohort\")\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example patient trajectory\n",
        "Sample a single patient trajectory and pivot it to wide format to inspect typical vital trends.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_patient = measurement_counts.idxmax()\n",
        "example_ts = pivot_timeseries(timeseries_dict[example_patient])\n",
        "selected_vars = [\"HR\", \"SysABP\", \"DiasABP\", \"RespRate\", \"SaO2\"]\n",
        "\n",
        "fig, axes = plt.subplots(len(selected_vars), 1, figsize=(10, 12), sharex=True)\n",
        "for ax, var in zip(axes, selected_vars):\n",
        "    if var in example_ts.columns:\n",
        "        ax.plot(example_ts.index, example_ts[var], marker=\"o\", linewidth=1)\n",
        "        ax.set_ylabel(var)\n",
        "    else:\n",
        "        ax.text(0.5, 0.5, \"Not recorded\", ha=\"center\", va=\"center\")\n",
        "        ax.set_ylabel(var)\n",
        "    ax.grid(True, axis=\"y\", linestyle=\":\", linewidth=0.5)\n",
        "axes[-1].set_xlabel(\"Hours since ICU admission\")\n",
        "fig.suptitle(f\"Patient {example_patient} vital trends (densest record)\")\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.95)\n",
        "example_ts[selected_vars].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "- Fit quick baseline mortality models (e.g., logistic regression) using the horizon summaries to quantify signal.\n",
        "- Explore SHAP/feature importances per ICU type to catch cohort-specific effects.\n",
        "- Extend the pipeline to include `set-b` for external validation and stress-test the imputation strategy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Outcomes and mortality labels\n",
        "Merge `Outcomes-a.txt` to attach SAPS-I / SOFA severity scores and mortality indicators to the demographic descriptors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTCOMES_PATH = DATA_DIR / \"Outcomes-a.txt\"\n",
        "outcomes_df = pd.read_csv(OUTCOMES_PATH)\n",
        "\n",
        "# Ensure RecordID is numeric for consistent joins\n",
        "general_info_df[\"RecordID\"] = general_info_df[\"RecordID\"].astype(int)\n",
        "outcomes_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mortality_merged = (\n",
        "    general_info_df.merge(\n",
        "        outcomes_df,\n",
        "        on=\"RecordID\",\n",
        "        how=\"inner\",\n",
        "        validate=\"one_to_one\",\n",
        "    )\n",
        "    .assign(\n",
        "        mortality_label=lambda d: d[\"In-hospital_death\"].map({0: \"Survivor\", 1: \"Non-survivor\"})\n",
        "    )\n",
        ")\n",
        "\n",
        "mortality_merged[\"measurement_count\"] = mortality_merged[\"RecordID\"].map(measurement_counts)\n",
        "\n",
        "mortality_merged.filter(\n",
        "    [\n",
        "        \"RecordID\",\n",
        "        \"Age\",\n",
        "        \"Gender\",\n",
        "        \"ICUType\",\n",
        "        \"SAPS-I\",\n",
        "        \"SOFA\",\n",
        "        \"Length_of_stay\",\n",
        "        \"In-hospital_death\",\n",
        "        \"mortality_label\",\n",
        "        \"measurement_count\",\n",
        "    ]\n",
        ").head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Survivors vs. non-survivors\n",
        "Quantify class balance and contrast the severity descriptors / measurement coverage between outcome groups.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mortality_counts = mortality_merged[\"mortality_label\"].value_counts().rename_axis(\"Outcome\")\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "sns.barplot(x=mortality_counts.index, y=mortality_counts.values, ax=ax, palette=\"Set2\")\n",
        "ax.set_ylabel(\"Patients\")\n",
        "ax.set_title(\"Outcome distribution\")\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt=\"%d\", padding=3)\n",
        "plt.tight_layout()\n",
        "mortality_counts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "comparison_cols = [\"Age\", \"SAPS-I\", \"SOFA\", \"Length_of_stay\", \"measurement_count\"]\n",
        "\n",
        "survival_summary = (\n",
        "    mortality_merged.groupby(\"mortality_label\")[comparison_cols]\n",
        "    .agg([\"mean\", \"median\", \"std\"])\n",
        "    .round(2)\n",
        ")\n",
        "survival_summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
        "plot_features = [\"Age\", \"SAPS-I\", \"measurement_count\"]\n",
        "\n",
        "def plot_kde(ax, feature):\n",
        "    sns.kdeplot(\n",
        "        data=mortality_merged,\n",
        "        x=feature,\n",
        "        hue=\"mortality_label\",\n",
        "        fill=True,\n",
        "        common_norm=False,\n",
        "        alpha=0.4,\n",
        "        ax=ax,\n",
        "    )\n",
        "    ax.set_title(f\"{feature} distribution\")\n",
        "    ax.set_xlabel(feature)\n",
        "\n",
        "for axis, feature in zip(axes, plot_features):\n",
        "    plot_kde(axis, feature)\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "icu_map = {\n",
        "    1: \"CCU\",\n",
        "    2: \"Cardiac Surg\",\n",
        "    3: \"MICU\",\n",
        "    4: \"SICU\",\n",
        "}\n",
        "\n",
        "icu_df = mortality_merged.assign(ICUTypeLabel=mortality_merged[\"ICUType\"].map(icu_map))\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "sns.countplot(data=icu_df, x=\"ICUTypeLabel\", hue=\"mortality_label\", ax=ax)\n",
        "ax.set_xlabel(\"ICU type\")\n",
        "ax.set_ylabel(\"Patients\")\n",
        "ax.set_title(\"Outcome by ICU type\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Horizon-based summary statistics\n",
        "Aggregate vital/lab time series over clinically meaningful windows (first 6h and 24h) to obtain fixed-length features suitable for downstream modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HORIZONS = [6, 24]\n",
        "SUMMARY_VARS = [\"HR\", \"SysABP\", \"DiasABP\", \"MAP\", \"RespRate\", \"SaO2\", \"Temp\", \"WBC\", \"Creatinine\", \"Lactate\"]\n",
        "\n",
        "\n",
        "def summarize_patient_timeseries(ts: pd.DataFrame, horizons: list[int], variables: list[str]) -> dict:\n",
        "    summary = {}\n",
        "    if ts.empty:\n",
        "        return summary\n",
        "\n",
        "    ts = ts.copy()\n",
        "    ts[\"value\"] = pd.to_numeric(ts[\"value\"], errors=\"coerce\")\n",
        "\n",
        "    for horizon in horizons:\n",
        "        subset = ts[ts[\"time_hours\"] <= horizon]\n",
        "        if subset.empty:\n",
        "            continue\n",
        "\n",
        "        pivoted = pivot_timeseries(subset)\n",
        "        for var in variables:\n",
        "            if var not in pivoted.columns:\n",
        "                continue\n",
        "            series = pd.to_numeric(pivoted[var], errors=\"coerce\")\n",
        "            summary[f\"{var}_mean_{horizon}h\"] = series.mean()\n",
        "            summary[f\"{var}_std_{horizon}h\"] = series.std()\n",
        "            last_valid = series.dropna()\n",
        "            summary[f\"{var}_last_{horizon}h\"] = last_valid.iloc[-1] if not last_valid.empty else np.nan\n",
        "    return summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_rows = []\n",
        "for pid, ts in timeseries_dict.items():\n",
        "    stats = summarize_patient_timeseries(ts, HORIZONS, SUMMARY_VARS)\n",
        "    stats[\"RecordID\"] = pid\n",
        "    summary_rows.append(stats)\n",
        "\n",
        "summary_feature_df = pd.DataFrame(summary_rows).set_index(\"RecordID\")\n",
        "summary_feature_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "summary_with_labels = mortality_merged.set_index(\"RecordID\").join(summary_feature_df)\n",
        "\n",
        "selected_summary_cols = [\n",
        "    \"HR_mean_6h\",\n",
        "    \"HR_last_6h\",\n",
        "    \"MAP_mean_24h\",\n",
        "    \"SaO2_mean_24h\",\n",
        "    \"Creatinine_mean_24h\",\n",
        "    \"Lactate_mean_24h\",\n",
        "]\n",
        "\n",
        "summary_with_labels.groupby(\"mortality_label\")[selected_summary_cols].mean().round(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "melt_cols = [\"HR_mean_6h\", \"MAP_mean_24h\", \"SaO2_mean_24h\", \"Creatinine_mean_24h\"]\n",
        "plot_df = summary_with_labels.reset_index()[[\"mortality_label\", *melt_cols]].melt(\n",
        "    id_vars=\"mortality_label\", var_name=\"feature\", value_name=\"value\"\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "sns.boxplot(data=plot_df, x=\"feature\", y=\"value\", hue=\"mortality_label\", ax=ax)\n",
        "plt.xticks(rotation=20)\n",
        "ax.set_ylabel(\"Value\")\n",
        "ax.set_title(\"Horizon summary features by outcome\")\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Missingness-aware imputation plan\n",
        "Treat high-missing labs (e.g., troponins) differently from frequently collected vitals by using population-level medians plus missingness indicators for the former, and simple per-feature medians for the latter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "high_missing_features = missingness_df.query(\"missing_rate >= 0.8\").index.tolist()\n",
        "frequent_features = missingness_df.query(\"missing_rate < 0.4\").index.tolist()\n",
        "\n",
        "\n",
        "def infer_feature_name(summary_col: str) -> str:\n",
        "    return summary_col.split(\"_\")[0]\n",
        "\n",
        "\n",
        "def impute_summary_features(summary_df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    imputed = summary_df.copy()\n",
        "    imputation_meta = []\n",
        "\n",
        "    for col in summary_df.columns:\n",
        "        feature = infer_feature_name(col)\n",
        "        category = (\n",
        "            \"high_missing_lab\"\n",
        "            if feature in high_missing_features\n",
        "            else (\"frequent_vital\" if feature in frequent_features else \"mid_missing\")\n",
        "        )\n",
        "        series = summary_df[col]\n",
        "        missing_rate = series.isna().mean()\n",
        "        if series.notna().sum() == 0:\n",
        "            continue\n",
        "        fill_value = series.median()\n",
        "        imputed[col] = series.fillna(fill_value)\n",
        "        if category == \"high_missing_lab\":\n",
        "            imputed[f\"{col}_was_missing\"] = series.isna().astype(int)\n",
        "        imputation_meta.append(\n",
        "            {\n",
        "                \"feature_column\": col,\n",
        "                \"base_feature\": feature,\n",
        "                \"category\": category,\n",
        "                \"missing_rate\": missing_rate,\n",
        "                \"fill_value\": round(fill_value, 3),\n",
        "            }\n",
        "        )\n",
        "    return imputed, pd.DataFrame(imputation_meta)\n",
        "\n",
        "\n",
        "imputed_summary_df, imputation_plan_df = impute_summary_features(summary_feature_df)\n",
        "imputation_plan_df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imputed_summary_df.head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
